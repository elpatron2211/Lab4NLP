{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f1cdd30",
   "metadata": {},
   "source": [
    "Paulo Sánchez\n",
    "\n",
    "\n",
    "Juan M. González-Campo\n",
    "\n",
    "\n",
    "Pedro Marroquín"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "83d4878b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=corpus = \"\"\"\n",
    "On a warm spring morning, the city slowly came to life. The streets were bathed in golden light as the first commuters began their daily routines. Shops opened their doors, the aroma of freshly brewed coffee wafting from the corner cafés. Joggers passed through the park, nodding politely at each other, while newspaper vendors shouted out headlines to the early risers. Everything moved with a quiet rhythm, as if the city itself was taking a deep breath before the rush began.\n",
    "\n",
    "At the university, the campus buzzed with energy. Students hurried across the lawns with backpacks slung over one shoulder, balancing coffee cups and textbooks. In lecture halls, professors prepared their presentations, flipping through slides and checking microphones. The library, though quieter, was no less active—pages turned rapidly, keyboards clicked in steady patterns, and study groups gathered around large wooden tables, whispering ideas and scribbling equations on notepads. The smell of ink, paper, and a hint of stress hung in the air.\n",
    "\n",
    "Meanwhile, in the countryside just outside the city, life moved at a slower pace. Farmers tended to their crops with practiced ease, guiding tractors through rows of green fields under the watchful gaze of distant hills. Children ran barefoot on dirt roads, chasing each other under the sun, their laughter echoing through the valley. The village storekeeper arranged fresh produce on wooden crates, greeting every passerby with a smile and a nod. Unlike the hurried tempo of the city, the countryside offered a comforting stillness that many longed for but rarely experienced.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ac041f",
   "metadata": {},
   "source": [
    "# Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e6a25ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['on', 'a', 'warm', 'spring', 'morning', 'the', 'city', 'slowly', 'came', 'to']\n"
     ]
    }
   ],
   "source": [
    "#Preprocesamiento del corpus \n",
    "import re\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text.split(' ')\n",
    "preprocessed_corpus = preprocess_text(corpus)\n",
    "print(preprocessed_corpus[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "46fd4f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math \n",
    "\n",
    "class bigram:\n",
    "    def __init__(self, corpus):\n",
    "        \"\"\"\n",
    "        Inicializa el modelo de bigramas con un corpus de texto.\n",
    "        \"\"\"\n",
    "        self.corpus = corpus\n",
    "        self.unigram_counts = defaultdict(int)\n",
    "        self.bigram_counts = defaultdict(int)\n",
    "        self.tokens = preprocess_text(corpus)\n",
    "        self.total_palabras = len(self.tokens)\n",
    "        self._train()\n",
    "\n",
    "    def _train(self):\n",
    "        \"\"\"\n",
    "        Entrena el modelo de bigramas contando los unigramas y bigramas\n",
    "        \"\"\"\n",
    "        \n",
    "        # Contar unigramas y bigramas\n",
    "        for i in range(len(self.tokens) - 1):\n",
    "            self.unigram_counts[self.tokens[i]] += 1\n",
    "            bigram = (self.tokens[i], self.tokens[i + 1])\n",
    "            self.bigram_counts[bigram] += 1\n",
    "        # Contar el último token\n",
    "        self.unigram_counts[self.tokens[-1]] += 1\n",
    "\n",
    "        # Para g\n",
    "\n",
    "    def bigram_prob(self, word1, word2):\n",
    "        \"\"\"\n",
    "        Calcula la probabilidad de un bigrama P(word2 | word1)\n",
    "        \"\"\"\n",
    "        bigram = (word1, word2)\n",
    "        if self.unigram_counts[word1] == 0:\n",
    "            return 0.0\n",
    "        return self.bigram_counts[bigram] / self.unigram_counts[word1]\n",
    "    \n",
    "   \n",
    "    \n",
    "    def bigram_prob_laplace(self, w1, w2):\n",
    "        \"\"\"\n",
    "        Probabilidad con suavizado de Laplace (add-one)\n",
    "        \"\"\"\n",
    "        V = len(self.unigram_counts)\n",
    "        return (self.bigram_counts[(w1, w2)] + 1) / (self.unigram_counts[w1] + V)\n",
    "    \n",
    "    def bigram_prob_add_k(self, w1, w2, k=0.01):\n",
    "        V = len(self.unigram_counts)\n",
    "        return (self.bigram_counts[(w1, w2)] + k) / (self.unigram_counts[w1] + k * V)\n",
    "    \n",
    "    def prob_sentence(self, sentence, method='normal', k=0.01):\n",
    "        \"\"\"\n",
    "        Calcula la probabilidad de una oración dada\n",
    "        \"\"\"\n",
    "        words = preprocess_text(sentence)\n",
    "        prob = 1.0\n",
    "        for i in range(len(words) - 1):\n",
    "            if method == 'normal':\n",
    "                prob *= self.bigram_prob(words[i], words[i + 1])\n",
    "            elif method == 'laplace':\n",
    "                prob *= self.bigram_prob_laplace(words[i], words[i + 1])\n",
    "            elif method == 'add_k':\n",
    "                prob *= self.bigram_prob_add_k(words[i], words[i + 1], k)\n",
    "        return prob\n",
    "    \n",
    "    def entropy(self):\n",
    "        \"\"\"\n",
    "        Calcula la entropía del modelo de bigramas\n",
    "        \"\"\"\n",
    "        entropy = 0.0\n",
    "        N = self.total_palabras-1\n",
    "        for i in range(N):\n",
    "            word1 = self.tokens[i]\n",
    "            word2 = self.tokens[i + 1]\n",
    "            prob = self.bigram_prob(word1, word2)\n",
    "            if prob > 0:\n",
    "                entropy -= math.log2(prob)\n",
    "        return entropy / N\n",
    "    \n",
    "    def perplexity(self):\n",
    "        \"\"\"\n",
    "        Calcula la perplejidad del modelo de bigramas\n",
    "        \"\"\"\n",
    "        entropy_value = self.entropy()\n",
    "        return 2 ** entropy_value if entropy_value > 0 else float('inf')\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "650d951a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigramas:\n",
      "on: 4\n",
      "a: 8\n",
      "warm: 1\n",
      "spring: 1\n",
      "morning: 1\n",
      "the: 24\n",
      "city: 4\n",
      "slowly: 1\n",
      "came: 1\n",
      "to: 3\n",
      "life: 2\n",
      "streets: 1\n",
      "were: 1\n",
      "bathed: 1\n",
      "in: 5\n",
      "golden: 1\n",
      "light: 1\n",
      "as: 2\n",
      "first: 1\n",
      "commuters: 1\n",
      "began: 2\n",
      "their: 5\n",
      "daily: 1\n",
      "routines: 1\n",
      "shops: 1\n",
      "opened: 1\n",
      "doors: 1\n",
      "aroma: 1\n",
      "of: 6\n",
      "freshly: 1\n",
      "brewed: 1\n",
      "coffee: 2\n",
      "wafting: 1\n",
      "from: 1\n",
      "corner: 1\n",
      "cafés: 1\n",
      "joggers: 1\n",
      "passed: 1\n",
      "through: 4\n",
      "park: 1\n",
      "nodding: 1\n",
      "politely: 1\n",
      "at: 3\n",
      "each: 2\n",
      "other: 2\n",
      "while: 1\n",
      "newspaper: 1\n",
      "vendors: 1\n",
      "shouted: 1\n",
      "out: 1\n",
      "headlines: 1\n",
      "early: 1\n",
      "risers: 1\n",
      "everything: 1\n",
      "moved: 2\n",
      "with: 5\n",
      "quiet: 1\n",
      "rhythm: 1\n",
      "if: 1\n",
      "itself: 1\n",
      "was: 2\n",
      "taking: 1\n",
      "deep: 1\n",
      "breath: 1\n",
      "before: 1\n",
      "rush: 1\n",
      "university: 1\n",
      "campus: 1\n",
      "buzzed: 1\n",
      "energy: 1\n",
      "students: 1\n",
      "hurried: 2\n",
      "across: 1\n",
      "lawns: 1\n",
      "backpacks: 1\n",
      "slung: 1\n",
      "over: 1\n",
      "one: 1\n",
      "shoulder: 1\n",
      "balancing: 1\n",
      "cups: 1\n",
      "and: 6\n",
      "textbooks: 1\n",
      "lecture: 1\n",
      "halls: 1\n",
      "professors: 1\n",
      "prepared: 1\n",
      "presentations: 1\n",
      "flipping: 1\n",
      "slides: 1\n",
      "checking: 1\n",
      "microphones: 1\n",
      "library: 1\n",
      "though: 1\n",
      "quieter: 1\n",
      "no: 1\n",
      "less: 1\n",
      "activepages: 1\n",
      "turned: 1\n",
      "rapidly: 1\n",
      "keyboards: 1\n",
      "clicked: 1\n",
      "steady: 1\n",
      "patterns: 1\n",
      "study: 1\n",
      "groups: 1\n",
      "gathered: 1\n",
      "around: 1\n",
      "large: 1\n",
      "wooden: 2\n",
      "tables: 1\n",
      "whispering: 1\n",
      "ideas: 1\n",
      "scribbling: 1\n",
      "equations: 1\n",
      "notepads: 1\n",
      "smell: 1\n",
      "ink: 1\n",
      "paper: 1\n",
      "hint: 1\n",
      "stress: 1\n",
      "hung: 1\n",
      "air: 1\n",
      "meanwhile: 1\n",
      "countryside: 2\n",
      "just: 1\n",
      "outside: 1\n",
      "slower: 1\n",
      "pace: 1\n",
      "farmers: 1\n",
      "tended: 1\n",
      "crops: 1\n",
      "practiced: 1\n",
      "ease: 1\n",
      "guiding: 1\n",
      "tractors: 1\n",
      "rows: 1\n",
      "green: 1\n",
      "fields: 1\n",
      "under: 2\n",
      "watchful: 1\n",
      "gaze: 1\n",
      "distant: 1\n",
      "hills: 1\n",
      "children: 1\n",
      "ran: 1\n",
      "barefoot: 1\n",
      "dirt: 1\n",
      "roads: 1\n",
      "chasing: 1\n",
      "sun: 1\n",
      "laughter: 1\n",
      "echoing: 1\n",
      "valley: 1\n",
      "village: 1\n",
      "storekeeper: 1\n",
      "arranged: 1\n",
      "fresh: 1\n",
      "produce: 1\n",
      "crates: 1\n",
      "greeting: 1\n",
      "every: 1\n",
      "passerby: 1\n",
      "smile: 1\n",
      "nod: 1\n",
      "unlike: 1\n",
      "tempo: 1\n",
      "offered: 1\n",
      "comforting: 1\n",
      "stillness: 1\n",
      "that: 1\n",
      "many: 1\n",
      "longed: 1\n",
      "for: 1\n",
      "but: 1\n",
      "rarely: 1\n",
      "experienced: 1\n",
      "\n",
      "Bigramas:\n",
      "('on', 'a'): 1\n",
      "('a', 'warm'): 1\n",
      "('warm', 'spring'): 1\n",
      "('spring', 'morning'): 1\n",
      "('morning', 'the'): 1\n",
      "('the', 'city'): 4\n",
      "('city', 'slowly'): 1\n",
      "('slowly', 'came'): 1\n",
      "('came', 'to'): 1\n",
      "('to', 'life'): 1\n",
      "('life', 'the'): 1\n",
      "('the', 'streets'): 1\n",
      "('streets', 'were'): 1\n",
      "('were', 'bathed'): 1\n",
      "('bathed', 'in'): 1\n",
      "('in', 'golden'): 1\n",
      "('golden', 'light'): 1\n",
      "('light', 'as'): 1\n",
      "('as', 'the'): 1\n",
      "('the', 'first'): 1\n",
      "('first', 'commuters'): 1\n",
      "('commuters', 'began'): 1\n",
      "('began', 'their'): 1\n",
      "('their', 'daily'): 1\n",
      "('daily', 'routines'): 1\n",
      "('routines', 'shops'): 1\n",
      "('shops', 'opened'): 1\n",
      "('opened', 'their'): 1\n",
      "('their', 'doors'): 1\n",
      "('doors', 'the'): 1\n",
      "('the', 'aroma'): 1\n",
      "('aroma', 'of'): 1\n",
      "('of', 'freshly'): 1\n",
      "('freshly', 'brewed'): 1\n",
      "('brewed', 'coffee'): 1\n",
      "('coffee', 'wafting'): 1\n",
      "('wafting', 'from'): 1\n",
      "('from', 'the'): 1\n",
      "('the', 'corner'): 1\n",
      "('corner', 'cafés'): 1\n",
      "('cafés', 'joggers'): 1\n",
      "('joggers', 'passed'): 1\n",
      "('passed', 'through'): 1\n",
      "('through', 'the'): 2\n",
      "('the', 'park'): 1\n",
      "('park', 'nodding'): 1\n",
      "('nodding', 'politely'): 1\n",
      "('politely', 'at'): 1\n",
      "('at', 'each'): 1\n",
      "('each', 'other'): 2\n",
      "('other', 'while'): 1\n",
      "('while', 'newspaper'): 1\n",
      "('newspaper', 'vendors'): 1\n",
      "('vendors', 'shouted'): 1\n",
      "('shouted', 'out'): 1\n",
      "('out', 'headlines'): 1\n",
      "('headlines', 'to'): 1\n",
      "('to', 'the'): 1\n",
      "('the', 'early'): 1\n",
      "('early', 'risers'): 1\n",
      "('risers', 'everything'): 1\n",
      "('everything', 'moved'): 1\n",
      "('moved', 'with'): 1\n",
      "('with', 'a'): 2\n",
      "('a', 'quiet'): 1\n",
      "('quiet', 'rhythm'): 1\n",
      "('rhythm', 'as'): 1\n",
      "('as', 'if'): 1\n",
      "('if', 'the'): 1\n",
      "('city', 'itself'): 1\n",
      "('itself', 'was'): 1\n",
      "('was', 'taking'): 1\n",
      "('taking', 'a'): 1\n",
      "('a', 'deep'): 1\n",
      "('deep', 'breath'): 1\n",
      "('breath', 'before'): 1\n",
      "('before', 'the'): 1\n",
      "('the', 'rush'): 1\n",
      "('rush', 'began'): 1\n",
      "('began', 'at'): 1\n",
      "('at', 'the'): 1\n",
      "('the', 'university'): 1\n",
      "('university', 'the'): 1\n",
      "('the', 'campus'): 1\n",
      "('campus', 'buzzed'): 1\n",
      "('buzzed', 'with'): 1\n",
      "('with', 'energy'): 1\n",
      "('energy', 'students'): 1\n",
      "('students', 'hurried'): 1\n",
      "('hurried', 'across'): 1\n",
      "('across', 'the'): 1\n",
      "('the', 'lawns'): 1\n",
      "('lawns', 'with'): 1\n",
      "('with', 'backpacks'): 1\n",
      "('backpacks', 'slung'): 1\n",
      "('slung', 'over'): 1\n",
      "('over', 'one'): 1\n",
      "('one', 'shoulder'): 1\n",
      "('shoulder', 'balancing'): 1\n",
      "('balancing', 'coffee'): 1\n",
      "('coffee', 'cups'): 1\n",
      "('cups', 'and'): 1\n",
      "('and', 'textbooks'): 1\n",
      "('textbooks', 'in'): 1\n",
      "('in', 'lecture'): 1\n",
      "('lecture', 'halls'): 1\n",
      "('halls', 'professors'): 1\n",
      "('professors', 'prepared'): 1\n",
      "('prepared', 'their'): 1\n",
      "('their', 'presentations'): 1\n",
      "('presentations', 'flipping'): 1\n",
      "('flipping', 'through'): 1\n",
      "('through', 'slides'): 1\n",
      "('slides', 'and'): 1\n",
      "('and', 'checking'): 1\n",
      "('checking', 'microphones'): 1\n",
      "('microphones', 'the'): 1\n",
      "('the', 'library'): 1\n",
      "('library', 'though'): 1\n",
      "('though', 'quieter'): 1\n",
      "('quieter', 'was'): 1\n",
      "('was', 'no'): 1\n",
      "('no', 'less'): 1\n",
      "('less', 'activepages'): 1\n",
      "('activepages', 'turned'): 1\n",
      "('turned', 'rapidly'): 1\n",
      "('rapidly', 'keyboards'): 1\n",
      "('keyboards', 'clicked'): 1\n",
      "('clicked', 'in'): 1\n",
      "('in', 'steady'): 1\n",
      "('steady', 'patterns'): 1\n",
      "('patterns', 'and'): 1\n",
      "('and', 'study'): 1\n",
      "('study', 'groups'): 1\n",
      "('groups', 'gathered'): 1\n",
      "('gathered', 'around'): 1\n",
      "('around', 'large'): 1\n",
      "('large', 'wooden'): 1\n",
      "('wooden', 'tables'): 1\n",
      "('tables', 'whispering'): 1\n",
      "('whispering', 'ideas'): 1\n",
      "('ideas', 'and'): 1\n",
      "('and', 'scribbling'): 1\n",
      "('scribbling', 'equations'): 1\n",
      "('equations', 'on'): 1\n",
      "('on', 'notepads'): 1\n",
      "('notepads', 'the'): 1\n",
      "('the', 'smell'): 1\n",
      "('smell', 'of'): 1\n",
      "('of', 'ink'): 1\n",
      "('ink', 'paper'): 1\n",
      "('paper', 'and'): 1\n",
      "('and', 'a'): 2\n",
      "('a', 'hint'): 1\n",
      "('hint', 'of'): 1\n",
      "('of', 'stress'): 1\n",
      "('stress', 'hung'): 1\n",
      "('hung', 'in'): 1\n",
      "('in', 'the'): 2\n",
      "('the', 'air'): 1\n",
      "('air', 'meanwhile'): 1\n",
      "('meanwhile', 'in'): 1\n",
      "('the', 'countryside'): 2\n",
      "('countryside', 'just'): 1\n",
      "('just', 'outside'): 1\n",
      "('outside', 'the'): 1\n",
      "('city', 'life'): 1\n",
      "('life', 'moved'): 1\n",
      "('moved', 'at'): 1\n",
      "('at', 'a'): 1\n",
      "('a', 'slower'): 1\n",
      "('slower', 'pace'): 1\n",
      "('pace', 'farmers'): 1\n",
      "('farmers', 'tended'): 1\n",
      "('tended', 'to'): 1\n",
      "('to', 'their'): 1\n",
      "('their', 'crops'): 1\n",
      "('crops', 'with'): 1\n",
      "('with', 'practiced'): 1\n",
      "('practiced', 'ease'): 1\n",
      "('ease', 'guiding'): 1\n",
      "('guiding', 'tractors'): 1\n",
      "('tractors', 'through'): 1\n",
      "('through', 'rows'): 1\n",
      "('rows', 'of'): 1\n",
      "('of', 'green'): 1\n",
      "('green', 'fields'): 1\n",
      "('fields', 'under'): 1\n",
      "('under', 'the'): 2\n",
      "('the', 'watchful'): 1\n",
      "('watchful', 'gaze'): 1\n",
      "('gaze', 'of'): 1\n",
      "('of', 'distant'): 1\n",
      "('distant', 'hills'): 1\n",
      "('hills', 'children'): 1\n",
      "('children', 'ran'): 1\n",
      "('ran', 'barefoot'): 1\n",
      "('barefoot', 'on'): 1\n",
      "('on', 'dirt'): 1\n",
      "('dirt', 'roads'): 1\n",
      "('roads', 'chasing'): 1\n",
      "('chasing', 'each'): 1\n",
      "('other', 'under'): 1\n",
      "('the', 'sun'): 1\n",
      "('sun', 'their'): 1\n",
      "('their', 'laughter'): 1\n",
      "('laughter', 'echoing'): 1\n",
      "('echoing', 'through'): 1\n",
      "('the', 'valley'): 1\n",
      "('valley', 'the'): 1\n",
      "('the', 'village'): 1\n",
      "('village', 'storekeeper'): 1\n",
      "('storekeeper', 'arranged'): 1\n",
      "('arranged', 'fresh'): 1\n",
      "('fresh', 'produce'): 1\n",
      "('produce', 'on'): 1\n",
      "('on', 'wooden'): 1\n",
      "('wooden', 'crates'): 1\n",
      "('crates', 'greeting'): 1\n",
      "('greeting', 'every'): 1\n",
      "('every', 'passerby'): 1\n",
      "('passerby', 'with'): 1\n",
      "('a', 'smile'): 1\n",
      "('smile', 'and'): 1\n",
      "('a', 'nod'): 1\n",
      "('nod', 'unlike'): 1\n",
      "('unlike', 'the'): 1\n",
      "('the', 'hurried'): 1\n",
      "('hurried', 'tempo'): 1\n",
      "('tempo', 'of'): 1\n",
      "('of', 'the'): 1\n",
      "('city', 'the'): 1\n",
      "('countryside', 'offered'): 1\n",
      "('offered', 'a'): 1\n",
      "('a', 'comforting'): 1\n",
      "('comforting', 'stillness'): 1\n",
      "('stillness', 'that'): 1\n",
      "('that', 'many'): 1\n",
      "('many', 'longed'): 1\n",
      "('longed', 'for'): 1\n",
      "('for', 'but'): 1\n",
      "('but', 'rarely'): 1\n",
      "('rarely', 'experienced'): 1\n"
     ]
    }
   ],
   "source": [
    "bigrama = bigram(corpus)\n",
    "\n",
    "#Imprimir unigramas y bigramas\n",
    "print(\"Unigramas:\")\n",
    "for word, count in bigrama.unigram_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "print(\"\\nBigramas:\")\n",
    "for bigram, count in bigrama.bigram_counts.items():\n",
    "    print(f\"{bigram}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "535c3c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entropía del modelo de bigramas: 0.9304\n",
      "Perplejidad del modelo de bigramas: 1.9058\n"
     ]
    }
   ],
   "source": [
    "entropia = bigrama.entropy()\n",
    "print(f\"\\nEntropía del modelo de bigramas: {entropia:.4f}\")\n",
    "perplejidad = bigrama.perplexity()\n",
    "print(f\"Perplejidad del modelo de bigramas: {perplejidad:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a977ed1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probabilidades de bigramas con suavizado de Laplace:\n",
      "Probabilidad de la frase 'The students walked through the city.': 0.0000000001\n",
      "\n",
      "Probabilidades de bigramas con suavizado add-k:\n",
      "Probabilidad de la frase 'The students walked through the city.': 0.0000000004\n",
      "\n",
      "Probabilidades de bigramas sin suavizado:\n",
      "Probabilidad de la frase 'The students walked through the city.': 0.0000000000\n"
     ]
    }
   ],
   "source": [
    "# laplace\n",
    "\n",
    "frase_prueba = \"The students walked through the city.\"\n",
    "\n",
    "print(\"\\nProbabilidades de bigramas con suavizado de Laplace:\")\n",
    "prob_laplace = bigrama.prob_sentence(frase_prueba, method='laplace')\n",
    "print(f\"Probabilidad de la frase '{frase_prueba}': {prob_laplace:.10f}\")\n",
    "print(\"\\nProbabilidades de bigramas con suavizado add-k:\")\n",
    "prob_add_k = bigrama.prob_sentence(frase_prueba, method='add_k', k=0.01)\n",
    "print(f\"Probabilidad de la frase '{frase_prueba}': {prob_add_k:.10f}\")\n",
    "print(\"\\nProbabilidades de bigramas sin suavizado:\")\n",
    "prob_normal = bigrama.prob_sentence(frase_prueba, method='normal')\n",
    "print(f\"Probabilidad de la frase '{frase_prueba}': {prob_normal:.10f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65e9eed",
   "metadata": {},
   "source": [
    "## Actividad para compañeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e278547a",
   "metadata": {},
   "source": [
    "### La perplejidad baja cuando...\n",
    "a) El vocabulario es más grande \n",
    "\n",
    "\n",
    "b) El corpus es más corto\n",
    "\n",
    "\n",
    "c) El modelo predice mejor las palabras del texto "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cd1593",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
