{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f1cdd30",
   "metadata": {},
   "source": [
    "Paulo Sánchez\n",
    "\n",
    "\n",
    "Juan M. González-Campo\n",
    "\n",
    "\n",
    "Pedro Marroquín"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83d4878b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"\"\"Anyone living in the United States in the early 1990s and paying even\n",
    "a whisper of attention to the nightly news or a daily paper could be\n",
    "forgiven for having been scared out of his skin.\n",
    "The culprit was crime. It had been rising relentlessly—a graph\n",
    "plotting the crime rate in any American city over recent decades\n",
    "looked like a ski slope in profile—and it seemed now to herald the\n",
    "\n",
    "end of the world as we knew it. Death by gunfire, intentional and oth-\n",
    "erwise, had become commonplace. So too had carjacking and crack\n",
    "\n",
    "dealing, robbery and rape. Violent crime was a gruesome, constant\n",
    "companion. And things were about to get even worse. Much worse.\n",
    "All the experts were saying so.\n",
    "The cause was the so-called superpredator. For a time, he was\n",
    "everywhere. Glowering from the cover of newsweeklies. Swaggering\n",
    "his way through foot-thick government reports. He was a scrawny,\n",
    "big-city teenager with a cheap gun in his hand and nothing in his\n",
    "heart but ruthlessness. There were thousands out there just like him,\n",
    "\n",
    "F R E A KO N O M I C S\n",
    "we were told, a generation of killers about to hurl the country into\n",
    "deepest chaos.\n",
    "\n",
    "In 1995 the criminologist James Alan Fox wrote a report for the\n",
    "\n",
    "U.S. attorney general that grimly detailed the coming spike in mur-\n",
    "ders by teenagers. Fox proposed optimistic and pessimistic scenarios.\n",
    "\n",
    "In the optimistic scenario, he believed, the rate of teen homicides\n",
    "would rise another 15 percent over the next decade; in the pessimistic\n",
    "scenario, it would more than double. “The next crime wave will get so\n",
    "bad,” he said, “that it will make 1995 look like the good old days.”\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6a25ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anyone', 'living', 'in', 'the', 'united', 'states', 'in', 'the', 'early', 's']\n"
     ]
    }
   ],
   "source": [
    "#Preprocesamiento del corpus \n",
    "import re\n",
    "def preprocess_text(text):\n",
    "    # Volver a minuscula\n",
    "    text = text.lower()\n",
    "    # Puntuacion y caracteres especiales\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    #Eliminar palabras de una sola letra\n",
    "    text = re.sub(r'\\b\\w{1}\\b', '', text)\n",
    "    # Espacios en blanco\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    #Eliminar numeros\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    #Partir las oracion\n",
    "    text = text.split(' ')\n",
    "    return text\n",
    "preprocessed_corpus = preprocess_text(corpus)\n",
    "print(preprocessed_corpus[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46fd4f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "# Conteo de unigramas y bigramas\n",
    "unigram_counts = defaultdict(int)\n",
    "bigram_counts = defaultdict(int)\n",
    "\n",
    "for i in range(len(preprocessed_corpus) - 1):\n",
    "    unigram_counts[preprocessed_corpus[i]] += 1\n",
    "    bigram = (preprocessed_corpus[i], preprocessed_corpus[i + 1])\n",
    "    bigram_counts[bigram] += 1\n",
    "\n",
    "# Último token\n",
    "unigram_counts[preprocessed_corpus[-1]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "650d951a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigramas:\n",
      "anyone: 1\n",
      "living: 1\n",
      "in: 10\n",
      "the: 21\n",
      "united: 1\n",
      "states: 1\n",
      "early: 1\n",
      "s: 1\n",
      "and: 7\n",
      "paying: 1\n",
      "even: 2\n",
      "whisper: 1\n",
      "of: 6\n",
      "attention: 1\n",
      "to: 4\n",
      "nightly: 1\n",
      "news: 1\n",
      "or: 1\n",
      "daily: 1\n",
      "paper: 1\n",
      "could: 1\n",
      "be: 1\n",
      "forgiven: 1\n",
      "for: 3\n",
      "having: 1\n",
      "been: 2\n",
      "scared: 1\n",
      "out: 2\n",
      "his: 4\n",
      "skin: 1\n",
      "culprit: 1\n",
      "was: 5\n",
      "crime: 4\n",
      "it: 5\n",
      "had: 3\n",
      "rising: 1\n",
      "relentlesslya: 1\n",
      "graph: 1\n",
      "plotting: 1\n",
      "rate: 2\n",
      "any: 1\n",
      "american: 1\n",
      "city: 1\n",
      "over: 2\n",
      "recent: 1\n",
      "decades: 1\n",
      "looked: 1\n",
      "like: 3\n",
      "ski: 1\n",
      "slope: 1\n",
      "profileand: 1\n",
      "seemed: 1\n",
      "now: 1\n",
      "herald: 1\n",
      "end: 1\n",
      "world: 1\n",
      "as: 1\n",
      "we: 2\n",
      "knew: 1\n",
      "death: 1\n",
      "by: 2\n",
      "gunfire: 1\n",
      "intentional: 1\n",
      "oth: 1\n",
      "erwise: 1\n",
      "become: 1\n",
      "commonplace: 1\n",
      "so: 3\n",
      "too: 1\n",
      "carjacking: 1\n",
      "crack: 1\n",
      "dealing: 1\n",
      "robbery: 1\n",
      "rape: 1\n",
      "violent: 1\n",
      "gruesome: 1\n",
      "constant: 1\n",
      "companion: 1\n",
      "things: 1\n",
      "were: 4\n",
      "about: 2\n",
      "get: 2\n",
      "worse: 2\n",
      "much: 1\n",
      "all: 1\n",
      "experts: 1\n",
      "saying: 1\n",
      "cause: 1\n",
      "socalled: 1\n",
      "superpredator: 1\n",
      "time: 1\n",
      "he: 4\n",
      "everywhere: 1\n",
      "glowering: 1\n",
      "from: 1\n",
      "cover: 1\n",
      "newsweeklies: 1\n",
      "swaggering: 1\n",
      "way: 1\n",
      "through: 1\n",
      "footthick: 1\n",
      "government: 1\n",
      "reports: 1\n",
      "scrawny: 1\n",
      "bigcity: 1\n",
      "teenager: 1\n",
      "with: 1\n",
      "cheap: 1\n",
      "gun: 1\n",
      "hand: 1\n",
      "nothing: 1\n",
      "heart: 1\n",
      "but: 1\n",
      "ruthlessness: 1\n",
      "there: 2\n",
      "thousands: 1\n",
      "just: 1\n",
      "him: 1\n",
      "ko: 1\n",
      "told: 1\n",
      "generation: 1\n",
      "killers: 1\n",
      "hurl: 1\n",
      "country: 1\n",
      "into: 1\n",
      "deepest: 1\n",
      "chaos: 1\n",
      ": 3\n",
      "criminologist: 1\n",
      "james: 1\n",
      "alan: 1\n",
      "fox: 2\n",
      "wrote: 1\n",
      "report: 1\n",
      "us: 1\n",
      "attorney: 1\n",
      "general: 1\n",
      "that: 2\n",
      "grimly: 1\n",
      "detailed: 1\n",
      "coming: 1\n",
      "spike: 1\n",
      "mur: 1\n",
      "ders: 1\n",
      "teenagers: 1\n",
      "proposed: 1\n",
      "optimistic: 2\n",
      "pessimistic: 2\n",
      "scenarios: 1\n",
      "scenario: 2\n",
      "believed: 1\n",
      "teen: 1\n",
      "homicides: 1\n",
      "would: 2\n",
      "rise: 1\n",
      "another: 1\n",
      "percent: 1\n",
      "next: 2\n",
      "decade: 1\n",
      "more: 1\n",
      "than: 1\n",
      "double: 1\n",
      "wave: 1\n",
      "will: 2\n",
      "bad: 1\n",
      "said: 1\n",
      "make: 1\n",
      "look: 1\n",
      "good: 1\n",
      "old: 1\n",
      "days: 1\n",
      "\n",
      "Bigramas:\n",
      "('anyone', 'living'): 1\n",
      "('living', 'in'): 1\n",
      "('in', 'the'): 4\n",
      "('the', 'united'): 1\n",
      "('united', 'states'): 1\n",
      "('states', 'in'): 1\n",
      "('the', 'early'): 1\n",
      "('early', 's'): 1\n",
      "('s', 'and'): 1\n",
      "('and', 'paying'): 1\n",
      "('paying', 'even'): 1\n",
      "('even', 'whisper'): 1\n",
      "('whisper', 'of'): 1\n",
      "('of', 'attention'): 1\n",
      "('attention', 'to'): 1\n",
      "('to', 'the'): 1\n",
      "('the', 'nightly'): 1\n",
      "('nightly', 'news'): 1\n",
      "('news', 'or'): 1\n",
      "('or', 'daily'): 1\n",
      "('daily', 'paper'): 1\n",
      "('paper', 'could'): 1\n",
      "('could', 'be'): 1\n",
      "('be', 'forgiven'): 1\n",
      "('forgiven', 'for'): 1\n",
      "('for', 'having'): 1\n",
      "('having', 'been'): 1\n",
      "('been', 'scared'): 1\n",
      "('scared', 'out'): 1\n",
      "('out', 'of'): 1\n",
      "('of', 'his'): 1\n",
      "('his', 'skin'): 1\n",
      "('skin', 'the'): 1\n",
      "('the', 'culprit'): 1\n",
      "('culprit', 'was'): 1\n",
      "('was', 'crime'): 1\n",
      "('crime', 'it'): 1\n",
      "('it', 'had'): 1\n",
      "('had', 'been'): 1\n",
      "('been', 'rising'): 1\n",
      "('rising', 'relentlesslya'): 1\n",
      "('relentlesslya', 'graph'): 1\n",
      "('graph', 'plotting'): 1\n",
      "('plotting', 'the'): 1\n",
      "('the', 'crime'): 1\n",
      "('crime', 'rate'): 1\n",
      "('rate', 'in'): 1\n",
      "('in', 'any'): 1\n",
      "('any', 'american'): 1\n",
      "('american', 'city'): 1\n",
      "('city', 'over'): 1\n",
      "('over', 'recent'): 1\n",
      "('recent', 'decades'): 1\n",
      "('decades', 'looked'): 1\n",
      "('looked', 'like'): 1\n",
      "('like', 'ski'): 1\n",
      "('ski', 'slope'): 1\n",
      "('slope', 'in'): 1\n",
      "('in', 'profileand'): 1\n",
      "('profileand', 'it'): 1\n",
      "('it', 'seemed'): 1\n",
      "('seemed', 'now'): 1\n",
      "('now', 'to'): 1\n",
      "('to', 'herald'): 1\n",
      "('herald', 'the'): 1\n",
      "('the', 'end'): 1\n",
      "('end', 'of'): 1\n",
      "('of', 'the'): 1\n",
      "('the', 'world'): 1\n",
      "('world', 'as'): 1\n",
      "('as', 'we'): 1\n",
      "('we', 'knew'): 1\n",
      "('knew', 'it'): 1\n",
      "('it', 'death'): 1\n",
      "('death', 'by'): 1\n",
      "('by', 'gunfire'): 1\n",
      "('gunfire', 'intentional'): 1\n",
      "('intentional', 'and'): 1\n",
      "('and', 'oth'): 1\n",
      "('oth', 'erwise'): 1\n",
      "('erwise', 'had'): 1\n",
      "('had', 'become'): 1\n",
      "('become', 'commonplace'): 1\n",
      "('commonplace', 'so'): 1\n",
      "('so', 'too'): 1\n",
      "('too', 'had'): 1\n",
      "('had', 'carjacking'): 1\n",
      "('carjacking', 'and'): 1\n",
      "('and', 'crack'): 1\n",
      "('crack', 'dealing'): 1\n",
      "('dealing', 'robbery'): 1\n",
      "('robbery', 'and'): 1\n",
      "('and', 'rape'): 1\n",
      "('rape', 'violent'): 1\n",
      "('violent', 'crime'): 1\n",
      "('crime', 'was'): 1\n",
      "('was', 'gruesome'): 1\n",
      "('gruesome', 'constant'): 1\n",
      "('constant', 'companion'): 1\n",
      "('companion', 'and'): 1\n",
      "('and', 'things'): 1\n",
      "('things', 'were'): 1\n",
      "('were', 'about'): 1\n",
      "('about', 'to'): 2\n",
      "('to', 'get'): 1\n",
      "('get', 'even'): 1\n",
      "('even', 'worse'): 1\n",
      "('worse', 'much'): 1\n",
      "('much', 'worse'): 1\n",
      "('worse', 'all'): 1\n",
      "('all', 'the'): 1\n",
      "('the', 'experts'): 1\n",
      "('experts', 'were'): 1\n",
      "('were', 'saying'): 1\n",
      "('saying', 'so'): 1\n",
      "('so', 'the'): 1\n",
      "('the', 'cause'): 1\n",
      "('cause', 'was'): 1\n",
      "('was', 'the'): 1\n",
      "('the', 'socalled'): 1\n",
      "('socalled', 'superpredator'): 1\n",
      "('superpredator', 'for'): 1\n",
      "('for', 'time'): 1\n",
      "('time', 'he'): 1\n",
      "('he', 'was'): 2\n",
      "('was', 'everywhere'): 1\n",
      "('everywhere', 'glowering'): 1\n",
      "('glowering', 'from'): 1\n",
      "('from', 'the'): 1\n",
      "('the', 'cover'): 1\n",
      "('cover', 'of'): 1\n",
      "('of', 'newsweeklies'): 1\n",
      "('newsweeklies', 'swaggering'): 1\n",
      "('swaggering', 'his'): 1\n",
      "('his', 'way'): 1\n",
      "('way', 'through'): 1\n",
      "('through', 'footthick'): 1\n",
      "('footthick', 'government'): 1\n",
      "('government', 'reports'): 1\n",
      "('reports', 'he'): 1\n",
      "('was', 'scrawny'): 1\n",
      "('scrawny', 'bigcity'): 1\n",
      "('bigcity', 'teenager'): 1\n",
      "('teenager', 'with'): 1\n",
      "('with', 'cheap'): 1\n",
      "('cheap', 'gun'): 1\n",
      "('gun', 'in'): 1\n",
      "('in', 'his'): 2\n",
      "('his', 'hand'): 1\n",
      "('hand', 'and'): 1\n",
      "('and', 'nothing'): 1\n",
      "('nothing', 'in'): 1\n",
      "('his', 'heart'): 1\n",
      "('heart', 'but'): 1\n",
      "('but', 'ruthlessness'): 1\n",
      "('ruthlessness', 'there'): 1\n",
      "('there', 'were'): 1\n",
      "('were', 'thousands'): 1\n",
      "('thousands', 'out'): 1\n",
      "('out', 'there'): 1\n",
      "('there', 'just'): 1\n",
      "('just', 'like'): 1\n",
      "('like', 'him'): 1\n",
      "('him', 'ko'): 1\n",
      "('ko', 'we'): 1\n",
      "('we', 'were'): 1\n",
      "('were', 'told'): 1\n",
      "('told', 'generation'): 1\n",
      "('generation', 'of'): 1\n",
      "('of', 'killers'): 1\n",
      "('killers', 'about'): 1\n",
      "('to', 'hurl'): 1\n",
      "('hurl', 'the'): 1\n",
      "('the', 'country'): 1\n",
      "('country', 'into'): 1\n",
      "('into', 'deepest'): 1\n",
      "('deepest', 'chaos'): 1\n",
      "('chaos', 'in'): 1\n",
      "('in', ''): 1\n",
      "('', 'the'): 1\n",
      "('the', 'criminologist'): 1\n",
      "('criminologist', 'james'): 1\n",
      "('james', 'alan'): 1\n",
      "('alan', 'fox'): 1\n",
      "('fox', 'wrote'): 1\n",
      "('wrote', 'report'): 1\n",
      "('report', 'for'): 1\n",
      "('for', 'the'): 1\n",
      "('the', 'us'): 1\n",
      "('us', 'attorney'): 1\n",
      "('attorney', 'general'): 1\n",
      "('general', 'that'): 1\n",
      "('that', 'grimly'): 1\n",
      "('grimly', 'detailed'): 1\n",
      "('detailed', 'the'): 1\n",
      "('the', 'coming'): 1\n",
      "('coming', 'spike'): 1\n",
      "('spike', 'in'): 1\n",
      "('in', 'mur'): 1\n",
      "('mur', 'ders'): 1\n",
      "('ders', 'by'): 1\n",
      "('by', 'teenagers'): 1\n",
      "('teenagers', 'fox'): 1\n",
      "('fox', 'proposed'): 1\n",
      "('proposed', 'optimistic'): 1\n",
      "('optimistic', 'and'): 1\n",
      "('and', 'pessimistic'): 1\n",
      "('pessimistic', 'scenarios'): 1\n",
      "('scenarios', 'in'): 1\n",
      "('the', 'optimistic'): 1\n",
      "('optimistic', 'scenario'): 1\n",
      "('scenario', 'he'): 1\n",
      "('he', 'believed'): 1\n",
      "('believed', 'the'): 1\n",
      "('the', 'rate'): 1\n",
      "('rate', 'of'): 1\n",
      "('of', 'teen'): 1\n",
      "('teen', 'homicides'): 1\n",
      "('homicides', 'would'): 1\n",
      "('would', 'rise'): 1\n",
      "('rise', 'another'): 1\n",
      "('another', ''): 1\n",
      "('', 'percent'): 1\n",
      "('percent', 'over'): 1\n",
      "('over', 'the'): 1\n",
      "('the', 'next'): 2\n",
      "('next', 'decade'): 1\n",
      "('decade', 'in'): 1\n",
      "('the', 'pessimistic'): 1\n",
      "('pessimistic', 'scenario'): 1\n",
      "('scenario', 'it'): 1\n",
      "('it', 'would'): 1\n",
      "('would', 'more'): 1\n",
      "('more', 'than'): 1\n",
      "('than', 'double'): 1\n",
      "('double', 'the'): 1\n",
      "('next', 'crime'): 1\n",
      "('crime', 'wave'): 1\n",
      "('wave', 'will'): 1\n",
      "('will', 'get'): 1\n",
      "('get', 'so'): 1\n",
      "('so', 'bad'): 1\n",
      "('bad', 'he'): 1\n",
      "('he', 'said'): 1\n",
      "('said', 'that'): 1\n",
      "('that', 'it'): 1\n",
      "('it', 'will'): 1\n",
      "('will', 'make'): 1\n",
      "('make', ''): 1\n",
      "('', 'look'): 1\n",
      "('look', 'like'): 1\n",
      "('like', 'the'): 1\n",
      "('the', 'good'): 1\n",
      "('good', 'old'): 1\n",
      "('old', 'days'): 1\n"
     ]
    }
   ],
   "source": [
    "#Imprimir unigramas y bigramas\n",
    "print(\"Unigramas:\")\n",
    "for word, count in unigram_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "print(\"\\nBigramas:\")\n",
    "for bigram, count in bigram_counts.items():\n",
    "    print(f\"{bigram}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "535c3c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropía (sin smoothing): 1.0291\n",
      "Perplejidad (sin smoothing): 2.0407\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# Probabilidad bigrama sin smoothing\n",
    "prob_bigrams = {}\n",
    "log_prob_sum = 0\n",
    "N = len(preprocessed_corpus) - 1  # número de bigramas\n",
    "\n",
    "for i in range(len(preprocessed_corpus) - 1):\n",
    "    w1, w2 = preprocessed_corpus[i], preprocessed_corpus[i+1]\n",
    "    bigram = (w1, w2)\n",
    "    prob = bigram_counts[bigram] / unigram_counts[w1]\n",
    "    prob_bigrams[bigram] = prob\n",
    "    log_prob_sum += -math.log2(prob)  # para entropía\n",
    "\n",
    "entropy = log_prob_sum / N\n",
    "perplexity = 2 ** entropy\n",
    "print(f\"Entropía (sin smoothing): {entropy:.4f}\")\n",
    "print(f\"Perplejidad (sin smoothing): {perplexity:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
